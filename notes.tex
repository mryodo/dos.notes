\documentclass{mynotes}


\title{Density of States of Hodge Laplacians: Decomposition effects and Sparsification of SC}

\author[1]{ Tony Savostianov }

\affil[1]{ RWTH, Aachen   \\ email: \email{a.s.savostyanov@gmail.com} }

\keywords{density of states, simplicial complexes, sparsification, generalized effective resistance}

\input{shortcuts.tex}

\begin{document}

\maketitle


\chapter{Introduction}

Well, it would be nice to have one. 

You know, somewhere here, maybe\dots


\chapter{ Graphs and Simplicial Complexes }

Simplicial complex \( \mc K \) is a higher-order generalization of the classical graph model with pair-wise interactions with a rich set of topological descriptors. Specifically, let \( \V 0 = \{ v_1, \dots v_{m_0} \} \) be a set of nodes; then \( \mc K \) is a collection of subsets (simplices) \( \sigma \) of nodes from \( \V 0 \) such that all the subsets of \( \sigma \) are simplices in \( \mc K \) too.
We refer to a simplex made out of \( k + 1 \) nodes \( \sigma = [ v_{i_1}, \ldots v_{i_{k+1}} ] \) as being of order \( k \)%, and write \( \dim \sigma = k \); 
the set of all the simplices of order \( k \) in the complex \( \mc K \) is denoted by \( \V k \). Thus, \( \V 0 \) are the vertices of \( \mc K \), \( \V 1 \) are edges between pairs of vertices, \( \V 2 \) triangles connecting three vertices, and so on. We let \( m_k = | \V k | \) denote the cardinality of \( \V k\).

Each set of simplices \( \V k = \left\{ \sigma_1, \dots \sigma_{ m_k } \right\} \) induces a linear space of formal sums over the simplicies \( C_k (\mc K) = \left\{  \sum_{i=1}^{ m_k } \alpha_i \sigma_i  \mid \alpha_i \in \ds R \right\} \) referred to as \textit{chain space}; in particular,  \( C_0 ( \mc K ) \) is known as the space of vertex states and \( C_1 ( \mc K ) \) as the space of edge flows. Simplices of different orders are related through the boundaries operators \( \partial_k \) mapping the simplex to its boundary; formally, \( \partial_k : C_k ( \mc K ) \mapsto C_{k-1} ( \mc K ) \) is defined through the alternating sum:
\begin{equation*}
      \partial_k [ v_1, v_2, \ldots v_k ] = \sum_{i=1}^k (-1)^{i-1} [ v_1, \ldots v_{i-1}, v_{i+1}, \ldots v_k ] 
\end{equation*} 
By fixing an ordering for \( \V k \) we can fix a canonical basis for \( C_k(\mc K)\) and represent each boundary operator as a matrix  \( B_k \in \mathrm{Mat}_{ m_{k-1} \times m_k } \) with exactly \( k \) nonzero entries per each column, being either \( +1 \) or \( -1 \). For these matrices, the fundamental property of topology holds: \textit{the boundary of the boundary is zero}, {\cite[Thm.~5.7]{Lim15}}:
\begin{equation}
      \label{eq:bkbk1}
      B_k B_{k+1} = 0 
\end{equation}
The matrix representation \( B_k \) of the boundary operator \( \partial_k \) requires fixing an ordering of the simplices in \( \V k \) and \( \V{k-1} \). As it will be particularly relevant for the purpose of this work, we emphasize that we order triangles and edges as follows: triangles in \( \V 2 \) are oriented in such a way that the first edge (in terms of the ordering of \( \V 1 \)) in each triangle is positively acted upon by \( B_2 \), i.e.\ the first non-zero entry in each column of \(B_2 \) is \( +1 \), \Cref{fig:orientation}. 

\input{figures/simplicialcomplex.tex}

The following definitions introduce the fundamental concepts of \(k\)-th homology group and \(k\)-th order Laplacian.  See \cite{Lim15} e.g.\ for more details. 

\begin{definition}[Homology group and higher-order Laplacian]
      Since \( \im B_{k+1} \subset \ker B_k \), the quotient space \( \mc H_k =  \sfrac{ \ker B_k }{ \im B_{k+1}} \), known as \( k\)-th homology group, is correctly defined and the following isomorphisms hold 
    \begin{equation*}
            \mc H_k \cong \ker B_k \cap \ker B_{k+1}^\top \cong \ker \left( B_k^\top B_k + B_{k+1} B_{k+1}^\top \right).
      \end{equation*}

      The matrix \( L_k = B_k^\top B_k + B_{k+1} B_{k+1}^\top \) is called the \(k\)-th order \emph{Laplacian operator}; the two terms \( \Ld k =  B_k^\top B_k \) and \( \Lu k = B_{k+1} B_{k+1}^\top \) are referred to as the \emph{down-Laplacian} and the \emph{up-Laplacian}, respectively.
\end{definition}

The homology group \( \mc H_k \) describes the \(k\)-th topology of the simplicial complex \( \mc K \): \( \beta_k = \dim \mc H_k = \dim \ker L_k \)  coincides exactly with the number of \(k\)-dimensional holes in the complex, known as the \emph{ \(k\)-th Betti number}. In the case \( k = 0 \), the operator \( L_0 = \Lu 0\) is exactly the classical graph Laplacian whose kernel corresponds to the \textit{connected components} of the graph, while \( \Ld 0  = 0 \). For \( k = 1 \) and \( k = 2\), the elements of \( \ker L_1 \) and \( \ker L_2\) describe the simplex 1-dimensional holes and voids respectively, and are frequently used in the analysis of trajectory data,~\cite{schaub2019random,benson2016higher}.


Although more frequently found in their purely combinatorial form, the definitions of simplicial complexes, homology groups, and higher-order Laplacians admit a generalization to the weighted case. For the sake of generality, in the rest of the work, we use the following notion of weighted boundary operators (and thus weighted simplicial complexes), as considered in e.g.~\cite{guglielmi2023quantifying}.

\begin{definition}[Weighted and normalised boundary matrices]
       For \textit{weight functions} \( w_k : \V k \mapsto \ds R_+ \cup \{ 0 \} \), define the diagonal weight matrix \( W_k \in \mathrm{Mat}_{ m_k \times m_k } \) as  \( (W_k)_{ii} = \sqrt{w_k(\sigma_i)}\). Then the  weighting scheme for the boundary operators upholding the Hodge algebras~\eqref{eq:bkbk1} is given by:
      \begin{equation}
            \label{eq:weighting}
            B_k \mapsto W_{k-1}^{-1} B_k W_k
      \end{equation}
\end{definition}

Note that, with the weighting scheme \Cref{eq:weighting}, the dimensionality of the homology group is preserved, \( \dim \ker L_k = \dim \ker \widehat L_k \),~\cite{guglielmi2023quantifying} as well as the fundamental property of topology \Cref{eq:bkbk1}. 


\chapter{ Density of States and Hodge Decomposition}

\todo{add some motivation for this discussion/transition}

Full spectral decomposition of \( \Lu k \) requires \( \mc O ( m_k^3) \) (or, more precisely, \( \mc O (m_k^\omega)\) where \( \omega \) is the exponent of matrix multiplication, \cite{banks2023pseudospectral}); accounting for the sparsity of \( \Lu k \), the actual computation time is even lower. As a result, even so we are going to use \( \mc O (m_k^3 )\) as a reference point to beat, the actual execution time should be carefully compared. 

Instead of the direct computation, one can exploit spectral density functions known as \emph{density of states} which encompass all the spectral information. Specifically,

\begin{definition}[Density of States]
      Fro a given symmetric matrix \( A = Q \Lambda Q^\top \) with \( Q^\top Q = I \) and diagonal \( \Lambda = \diag \left( \lambda_1, \dots \lambda_{n} \right) \), the \emph{spectral density} or \emph{density of states} (DoS)
      \begin{equation}
            \mu( \lambda \mid A ) = \frac{1}{n} \sum_{i=1}^{n} \delta \left( \lambda - \lambda_i \right)
      \end{equation}
      Additionally, let \( \b q_i \) be a corresponding unit eigenvector of \( A \) (such that \( A \b q_i = \lambda_i \b q_i \) and \( Q = \left( \b q_1 \mid \b q_2 \mid \dots \mid \b q_n \right)\)); then one can define a set of local (entry-wise) densities of states (\emph{LDoS}):
      \begin{equation}
            \mu_k ( \lambda \mid A ) = \sum_{i=1}^{n} \left| \b e_k^\top \b q_i \right|^2 \delta \left( \lambda - \lambda_i \right)
      \end{equation}
      with \( \b e_k \) being the corresponding versor. 
\end{definition}

Note that DoS \( \mu ( \lambda \mid A ) \) only describes the spectrum \( \sigma ( A ) \) while the family of LDoS \( \{ \mu_k (\lambda \mid A ) \} \) contain additionally eigenvectors \( \b q_i \). The exact computation of either DoS or LDoS still requires the full spectral decomposition; instead, one can try to approximate densities of states via Kernel Polynomial Method (KPM).%\todo{check the name of the method in Benson's paper}.

\section{ Chebyshev Approximation of DoS/LDoS }

Let us assume we transition from symmetric \( A \) to a symmetric \( H \) such that \( \sigma(H) \subseteq [-1, 1 ]\), e.g. by \( H = \frac{2}{ \lambda_{\max{}} ( A ) } A - I \). This allows us to assume that \( \mathrm{supp}\, \mu( \lambda \mid H ) \subseteq [-1, 1]\) and it can be decomposed into an orthonormal basis on \( [-1, 1]\). 

Specifically, let \( T_m(x) \) be a family of Chebyshev polynomials of the first kind iff:
\begin{equation}
      T_0(x) = 1, \quad T_1(x) = x, \qquad T_{m+1}(x) = 2x T_m(x) - T_{m-1}(x) 
\end{equation}
Polymonials \( T_m(x) \) are famously orthogonal on \( [-1, 1] \) in \(L_2\)-scalar product with the weight function \( w(x) = \frac{2}{(1+\delta_{0m})\pi \sqrt{1-x^2}}\)\todo{figure out how to write here the problem with \( m = 0 \) for the orthonormality}. Then, \( T^*_m(x) = w_m(x) T_m(x)\) form a dual Chebyshev basis, and one can write an expansion:
\begin{equation}
      \begin{aligned}
            \mu( \lambda \mid H ) & = \sum_{m=0}^{\infty} d_m T^*_m(\lambda)     \\
            \mu_k( \lambda \mid H ) & = \sum_{m=0}^{\infty} d_{mk} T^*_m(\lambda)   
      \end{aligned}
\end{equation}
Note that since \( T_m(x) \) are orthogonal to \( T^*_m(x) \), so 
\begin{equation}
      \begin{aligned}
            d_m = & \int T_m(\lambda) \mu(\lambda \mid H) d\lambda = \frac{1}{n} \sum_{i=1}^n T_m(\lambda_i) = \frac{1}{n} \mathrm{tr} (T_m(H)) \\
            d_{mk} = & \int T_m(\lambda) \mu_k(\lambda \mid H) d\lambda = \sum_{i=1}^n \left| \b e_k^\top \b q_i \right|^2 T_m(\lambda_i) = \left[ T_m( H ) \right]_{kk}
      \end{aligned}
\end{equation}
with 
\begin{equation}
      \begin{aligned}
            \ds E \left[ \b z^\top H \b z \right] = & \mathrm{tr}(H) \approx \frac{1}{N_z} \sum_{j=1}^{N_z} Z_j^\top H Z_j \\
            \ds E \left[ \b z \odot H \b z \right] = & \diag ( H ) \approx \frac{1}{N_z} \sum_{j=1}^{N_z} Z_j \odot H Z_j  
      \end{aligned}
\end{equation}
where each entry in \( \b z \) is i.i.d with zero mean and unit variance. 

Note that due to the recurrent definition, \( d_m = \frac{1}{n} \ds E \left[ \b z^\top T_m(H) \b z \right] = \frac{1}{n} \ds E \left[ \b z^\top \left( 2 H T_{m-1}(H) - T_{m-2}(H) \right) \b z \right] \), the computation of \( d_m \) requires only \emph{one} new \texttt{matvec} computation for \( H T_{m-1}(H) \b z \) since estimations for \( T_{m-1}(H) \b z \) and \( T_{m-2}(H) \b z \) are inherited from \( d_{m-1} \) and \( d_{m-2}\). As a result, the computational cost of each new moment \( d_m \) is \( \mc O( \texttt{nnz}(H))\), and, assuming we use \( M \) moments in the decomposition, the overall complexity is \( \mc O \left( N_z M \texttt{nnz}(H)  \right)\).

In the case of \( L_k \), we get \( \mc O \left( N_z M ( k m_k + (k+1)m_{k+1}) \right)\).

\section{ Spike problems and filtration }

\section{ Effects of the Hodge Decomposition }

\chapter{ Sparsification of Simplicial Complexes }

Simplicial complex \( \mc K \) typically has quite an intrinsic structure of the associated Laplacian operators \( L_k \) which becomes more and more complicated as \( \mc K \) becomes denser in the sense of complexes of order \( \mc K \). Instead, one can ask a simplifying question: can one find a sparser simplicial complex \( \mc L \) with a spectrally close operator \( L_k (\mc L )\)?

The overall idea of the sparsification is built upon the idea that a sparsifier can be subsampled from a given simplificial copmlex with high probability. Specifically: 
\begin{definition}[Spectral Approximation]
      The Hermitian matrix \( A \) is called \emph{spectrally \(\eps\)-close} to the Hermitian matrix \( B \), \( A \underset{\eps}{\approx} B \), if 
      % \begin{equation*}
            $( 1 - \eps ) B \preceq A \preceq ( 1 + \eps ) B $,
      % \end{equation*}
      where \( \succeq \) is the partial ordering induced by the positive definite cone, i.e. \( A \succeq B \) if \( A - B \) is positive semi-definite.
\end{definition}

\begin{remark}\label{rem:approx_error}
      Note that if \( A \underset{\eps}{\approx} B \), then one can directly bound the distance \( \| \b x_A - \b x_B \| \), where \( A \b x_A = \b f \) and \( B \b x_B = \b f\). Indeed, \( \b x_B = B^{-1} A \b x_A \) and \(\| \b x_A - \b x_B \| = \| \left( I - B^{-1}A \right) \b x_A \| \le \| I - B^{-1}A \| \| \b x_A \| \le  \| B^{-1} \| \cdot \| B - A \| \cdot \| \b x_A \| \le \eps \| B^{-1} \| \cdot \| B \| \cdot \| \b x_A \| = \eps \kappa(B) \| \b x_A \| \), with \( \kappa(B) \) being the condition number of \( B \). Thus, the relative error is controlled by the quality of the approximation \( \eps \) and the condition number \( \kappa(B )\). %This does not necessarily mean that one can use an approximation \( B \) to obtain a solution of \( A \b x = \b f\) (since obtaining a high-quality approximation for small \( \eps \) may be expensive), but implies that assuming one has a preconditioner for one of the matrices, one can use it to precondition the other.
\end{remark}

\begin{thm}[Simplicial Sparsification, \cite{osting2017spectral}] \label{thm:sparsify}
      Let \( \mc K \) be a simplicial complex restricted to its \(p\)-skeleton, \( \mc K = \bigcup_{i=0}^p \V i \).  Let   \( \Lu k (\mc K ) \) be its  \(k\)-th up-Laplacian and let \( m_k = | \V k | \). For any \( \eps > 0 \), a sparse simplicial complex \( \mc L \) can be sampled as follows:
      \begin{enumerate}[leftmargin=*, label=(\arabic*)]
            \item compute the probability measure \( \b p  \) on \( \V {k+1} \) proportional to the generalized resistance vector \( \b r = \diag \left( B_{k+1}^\top ( \Lu k )^\dagger B_{k+1} \right) \), where  $\diag(A)$ denotes the vector of the diagonal entries of $A$;
            \item sample \(q\) simplices \( \tau_i \) from \( \V {k+1}\) according to the probability measure \( \b p  \),  where $q$ is chosen so that  \( q ( m_k ) \ge 9 C^2 m_{k} \log ( m_{k} / \eps  )\), for some absolute constant  \( C>0 \);
            \item form a sparse simplicial complex \( \mc L \) with all the sampled simplexes of order \( k \) and all its faces with the weight \( \frac{ w_{k+1} (\tau_i) }{ q(m_k) \b p(\tau_i)  } \); weights of repeated simplices are accumulated.
      \end{enumerate}
      Then, with probability at least \(1/2\), the up-Laplacian of the sparsifier \( \mc L \) is \(\eps\)-close to the original one, i.e. it holds \( \Lu k (\mc L ) \underset{\eps}{\approx} \Lu k (\mc K) \).
\end{thm}

The bottleneck of the subsampling above is the construction of the appropriate measure \( \b p \) or, more precisely, generalized effective resistance \( \b r \). Indeed, one needs a fast pseudo-inverse operator \( \left(  \Lu k \right)^\dagger \) in order to compute \( \b r \).

\begin{remark}[Sensitivity of the Sparsification vis-a-vis sampling measure \( \b p \)]
      Compare \( \eps \) with \( \frac{1}{m_2}\): if below, you are fiiiiiiine

      INSERT FIGURE HERE
\end{remark}

\todo{we need to assume somewhere \( W_k = I \) for simplicity and do not forget about it}

\begin{thm}[GER through DoS]
      For a given simplicial complex \( mc K \) with the \(k\)-th order up-Laplacian \( \Lu k = B_{k+1} W_{k+1}^2 B_{k+1}^\top\), a generalized effective resistance \( r \) can be computed through family of local densities of states \( \{ \mu_i(\lambda \mid \Ld {k+1 }) \} \):
      \begin{equation}
            \b r_i = \int_{\ds R } (1 - \ds 1_0(\lambda)) \mu_i ( \lambda \mid \Ld {k+1} ) d\lambda 
      \end{equation}
\end{thm}
\begin{proof}
      Let \( B_{k+1} W_{k+1} = U S V^\top\) where \( S \) is diagonal and invertible and both \( U \) and \( V \) are orthogonal (so it is a truncated SVD decomposition of \( B_{k+1} W_{k+1} \) matrix with eliminated obsolete kernel). Then:
      \begin{equation}
            ( \Lu k )^\dagger = \left( B_{k+1} W_{k+1}^2 B_{k+1}^\top \right)^\dagger = \left( U S^2 U^\top \right)^\dagger = U S^{-2} U^\top
      \end{equation}
      \begin{equation}
            \begin{aligned}
                  \b r & = \diag \left( W_{k+1} B_{k+1}^\top ( \Lu k )^\dagger B_{k+1} W_{k+1} \right)  =  \\
                  & = \diag \left(  V S U^\top U S^{-2} U^\top U S V^\top \right) = \diag \left(  V V^\top \right)
            \end{aligned}
      \end{equation}
      As a result, \( \b r_i = \| V_{ i \cdot } \|^2 = \sum_j | v_{ij} |^2  \), so the \(i\)-th entry of the resistance is defined by the sum of square of \(i\)-th components of eigenvectors \( \b v_j \) of \( \Ld {k+1} = W_{k+1} B_{k+1}^\top B_{k+1} W_{k+1} \) operator where \( \b v_j \perp \ker \Ld {k+1} \).

      Note that 
      \begin{equation}
            \mu_i ( \lambda \mid \Ld {k+1} ) = \sum_{j=1}^{m_{k+1}} \left| \b e_i^\top \b q_j \right|^2 \delta \left( \lambda - \lambda_j \right)  = \sum_{j=1}^{m_{k+1}} \left| q_{ij} \right|^2 \delta \left( \lambda - \lambda_j \right) 
      \end{equation}
      so 
      \begin{equation}
            \begin{aligned}
                  \b r_i & = \| V_{ i \cdot } \|^2 = \sum_j | v_{ij} |^2 = \int_{ \ds R \backslash \{ 0 \} }  \sum_{j=1}^{m_{k+1}} \left| q_{ij} \right|^2 \delta \left( \lambda - \lambda_j \right)  d\lambda =\\
                  & = \int_{ \ds R \backslash \{ 0 \} } \mu_i ( \lambda \mid \Ld {k+1} ) d\lambda = \int_{\ds R } (1 - \ds 1_0(\lambda)) \mu_i ( \lambda \mid \Ld {k+1} ) d\lambda
            \end{aligned}
      \end{equation}
\end{proof}
\todo{check for the exact case}
\todo{error propagation}













\begin{comment}
\chapter{ Simplicial complexes }

A \emph{simplicial complex} \( \mc K \) on the vertices \( \{ v_1, v_2 \ldots v_n \} \) is a collection of simplices \( \sigma \), sets of nodes with the property that all the subsets of $\sigma$ are simplicies of $\mc K$ too.   
We refer to a simplex made out of $k$ nodes \( \sigma = [ v_{i_1}, \ldots v_{i_{k+1}} ] \) as being of order \( k \), and write \( \dim \sigma = k \); the set of all the simplices of order \( k \) in the complex \( \mc K \) is denoted by \( \V k \). Thus, \( \V 0 \) are the vertices of $\mc K$, \( \V 1 \) are edges between pairs of vertices, \( \V 2 \) triangles connecting three vertices, and so on. We let \( m_k = | \V k | \) denote the cardinality of \( \V k\).

Each set of simplices \( \V k = \left\{ \sigma_1, \dots \sigma_{ m_k } \right\} \) induces a linear space of formal sums over the simplicies \( C_k (\mc K) = \left\{  \sum_{i=1}^{ m_k } \alpha_i \sigma_i  \mid \alpha_i \in \ds R \right\} \) referred to as \textit{chain space}; in particular,  \( C_0 ( \mc K ) \) is known as the space of vertex states and \( C_1 ( \mc K ) \) as the space of edge flows. Simplices of different orders are related through the boundaries operators \( \partial_k \) mapping the simplex to its boundary; formally, \( \partial_k : C_k ( \mc K ) \mapsto C_{k-1} ( \mc K ) \) is defined through the alternating sum:
\begin{equation*}
      \partial_k [ v_1, v_2, \ldots v_k ] = \sum_{i=1}^k (-1)^{i-1} [ v_1, \ldots v_{i-1}, v_{i+1}, \ldots v_k ] 
\end{equation*} 
By fixing an ordering for \( \V k \) we can fix a canonical basis for \( C_k(\mc K)\) and represent each boundary operator as a matrix  \( B_k \in \mathrm{Mat}_{ m_{k-1} \times m_k } \) with exactly $k$ nonzero entries per each column, being either $+1$ or $-1$. For these matrices, the fundamental property of topology holds: \textit{the boundary of the boundary is zero}, {\cite[Thm.~5.7]{Lim15}}:
\begin{equation}
      \label{eq:bkbk1}
      B_k B_{k+1} = 0 
\end{equation}
The matrix representation $B_k$ of the boundary operator \( \partial_k \) requires fixing an ordering of the simplices in $\V k$ and $\V{k-1}$. As it will be particularly relevant for the purpose of this work, we emphasize that we order triangles and edges as follows: triangles in \( \V 2 \) are oriented in such a way that the first edge (in terms of the ordering of \( \V 1 \)) in each triangle is positively acted upon by $B_2$, i.e.\ the first non-zero entry in each column of \(B_2 \) is \( +1 \), \Cref{fig:orientation}. 

\begin{figure}[hbtp]
      \centering
      \begin{tikzpicture}
            \begin{scope}[shift={(-0.75, 0)}]
            \draw[fill = liberty, opacity = 0.4] (0,0) -- (1.5,0) -- (0.75, -1.5*3/4) -- cycle; 
            \draw[fill = liberty, opacity = 0.6] (0,0) -- (1.5,0) -- (0.75, 1.5*3/4) -- cycle; 

            \Vertex[x=0, y=0, label = 1, style={color = persimmon}, fontcolor = white, size = 0.4 ]{v1}
            \Vertex[x=1.5, y=0, label = 3, style={color = persimmon}, fontcolor = white, size = 0.4 ]{v2}
            \Vertex[x=0.75, y=-1.5*3/4, label = 2, style={color = persimmon}, fontcolor = white, size = 0.4 ]{v3}
            \Vertex[x=0.75, y=1.5*3/4, label = 4, style={color = persimmon}, fontcolor = white, size = 0.4 ]{v4}
            \Edge[Direct](v1)(v2)
            \Edge[Direct](v1)(v3)
            \Edge[Direct](v1)(v4)
            \Edge[Direct](v3)(v2)
            \Edge[Direct](v2)(v4)
            \node at (0.75, 1.5*3/4*1/3 ) { \AxisRotator[rotate=0] };
            \node at (0.75, -1.5*3/4*1/3 ) { \AxisRotator[rotate=-60] };
            \end{scope}

            \Vertex[x=2.5, y=1.5*3/4, label = 1, style={color = persimmon}, fontcolor = white, size = 0.4 ]{t1}
            \Vertex[x=4, y=1.5*3/4, label = 2, style={color = persimmon}, fontcolor = white, size = 0.4 ]{t2}
            \Vertex[x=2.5, y=0.9*3/4, label = 1, style={color = persimmon}, fontcolor = white, size = 0.4 ]{t3}
            \Vertex[x=4, y=0.9*3/4, label = 3, style={color = persimmon}, fontcolor = white, size = 0.4 ]{t4}
            \Vertex[x=2.5, y=0.3*3/4, label = 1, style={color = persimmon}, fontcolor = white, size = 0.4 ]{t5}
            \Vertex[x=4, y=0.3*3/4, label = 4, style={color = persimmon}, fontcolor = white, size = 0.4 ]{t6}
            \Vertex[x=2.5, y=-0.3*3/4, label = 2, style={color = persimmon}, fontcolor = white, size = 0.4 ]{t7}
            \Vertex[x=4, y=-0.3*3/4, label = 3, style={color = persimmon}, fontcolor = white, size = 0.4 ]{t8}
            \Vertex[x=2.5, y=-0.9*3/4, label = 3, style={color = persimmon}, fontcolor = white, size = 0.4 ]{t9}
            \Vertex[x=4, y=-0.9*3/4, label = 4, style={color = persimmon}, fontcolor = white, size = 0.4 ]{t10}
            \Edge[Direct](t1)(t2)
            \Edge[Direct](t3)(t4)
            \Edge[Direct](t5)(t6)
            \Edge[Direct](t7)(t8)
            \Edge[Direct](t9)(t10)

            \draw[->, line width = 1.0] (2.1, 1.9*3/4)--(2.1, -1.5*3/4);
            \draw[->, line width = 1.0] (2.1, 1.9*3/4)--(4.4, 1.9*3/4);
            \node[ anchor=south ] at ( 3.25, 1.9*3/4 ) { \small orientation };
            \node[ anchor = south, rotate = 90 ] at (2.1, 0.2*3/4 ) { \small ordering };

            \node[] at ( 8.25, 1.0 ) { \( B_2 \textcolor{liberty}{[1, 2, 3 ]} = \overbrace{\textcolor{red}{(+1)} [1, 2]}^{\substack{\text{1st in}\\\text{order}}} + (-1) [1, 3] + (+1) [2, 3] \) };
            \node[] at ( 8.25, -0.4 ) { \( B_2 \textcolor{liberty}{[1, 3, 4 ]} = \underbrace{\textcolor{red}{(+1)} [1, 3]}_{\substack{\text{1st in}\\\text{order}}} + (-1) [1, 4] + (+1) [3, 4] \) };  
      \end{tikzpicture}
      \caption{ Example of the simplicial complex with ordering and orientation: nodes from \( \V 0 \) in orange, triangles from \( \V 2 \) in blue. Orientation of edges and triangles is shown by arrows; the action of \( B_2 \) operator is given for both triangles.\label{fig:orientation}}
\end{figure}


The following definitions introduce the fundamental concepts of $k$-th homology group and $k$-th order Laplacian.  See \cite{Lim15} e.g.\ for more details. 

\begin{definition}[Homology group and higher-order Laplacian]
      Since \( \im B_{k+1} \subset \ker B_k \), the quotient space \( \mc H_k =  \sfrac{ \ker B_k }{ \im B_{k+1}} \), known as \( k\)-th homology group, is correctly defined and the following isomorphisms hold 
    \begin{equation*}
            \mc H_k \cong \ker B_k \cap \ker B_{k+1}^\top \cong \ker \left( B_k^\top B_k + B_{k+1} B_{k+1}^\top \right).
      \end{equation*}

      The matrix \( L_k = B_k^\top B_k + B_{k+1} B_{k+1}^\top \) is called the \(k\)-th order \emph{Laplacian operator}; the two terms \( \Ld k =  B_k^\top B_k \) and \( \Lu k = B_{k+1} B_{k+1}^\top \) are referred to as the \emph{down-Laplacian} and the \emph{up-Laplacian}, respectively.
\end{definition}

The homology group \( \mc H_k \) describes the \(k\)-th topology of the simplicial complex \( \mc K \): \( \beta_k = \dim \mc H_k = \dim \ker L_k \)  coincides exactly with the number of \(k\)-dimensional holes in the complex, known as the \emph{ \(k\)-th Betti number}. In the case \( k = 0 \), the operator \( L_0 = \Lu 0\) is exactly the classical graph Laplacian whose kernel corresponds to the \textit{connected components} of the graph, while \( \Ld 0  = 0 \). For \( k = 1 \) and \( k = 2\), the elements of \( \ker L_1 \) and \( \ker L_2\) describe the simplex 1-dimensional holes and voids respectively, and are frequently used in the analysis of trajectory data,~\cite{schaub2019random,benson2016higher}.


Although more frequently found in their purely combinatorial form, the definitions of simplicial complexes, homology groups, and higher-order Laplacians admit a generalization to the weighted case. For the sake of generality, in the rest of the work, we use the following notion of weighted boundary operators (and thus weighted simplicial complexes), as considered in e.g.~\cite{guglielmi2023quantifying}.

\begin{definition}[Weighted and normalised boundary matrices]
       For \textit{weight functions} \( w_k : \V k \mapsto \ds R_+ \cup \{ 0 \} \), define the diagonal weight matrix \( W_k \in \mathrm{Mat}_{ m_k \times m_k } \) as  \( (W_k)_{ii} = \sqrt{w_k(\sigma_i)}\). Then the  weighting scheme for the boundary operators upholding the Hodge algebras~\eqref{eq:bkbk1} is given by:
      \begin{equation}
            \label{eq:weighting}
            B_k \mapsto W_{k-1}^{-1} B_k W_k
      \end{equation}
\end{definition}

Note that, with the weighting scheme \Cref{eq:weighting}, the dimensionality of the homology group is preserved, \( \dim \ker L_k = \dim \ker \widehat L_k \),~\cite{guglielmi2023quantifying} as well as the fundamental property of topology \Cref{eq:bkbk1}. 


\chapter{ Density of States on Simplicial Complexes }

Spectral properties of higher-order Laplacian operators relate to various topological features REF; in the case of the classical graph Laplacian operator, various part of the spectrum and eigenvectors have been used to motif recognition, node importance, centrality measures, etc. 

At the same time, such spectral information is exceedingly expensive to compute. \cite{dong2019network} introduced the notion of spectral densities which can be efficiently approximated:

\begin{definition}[Density of States]
      Fro a given symmetric matrix\footnote{we need to ask something of this matrix} \( A = Q \Lambda Q^\top \) with \( Q^\top Q = I \) and diagonal \( \Lambda = \diag \left( \lambda_1, \dots \lambda_{n} \right) \), the \emph{spectral density} or \emph{density of states} (DoS)
      \begin{equation}
            \mu( \lambda \mid A ) = \frac{1}{n} \sum_{i=1}^{n} \delta \left( \lambda - \lambda_i \right)
      \end{equation}
      Additionally, let \( \b q_i \) be a corresponding unit eigenvector of \( A \) (such that \( A \b q_i = \lambda_i \b q_i \) and \( Q = \left( \b q_1 \mid \b q_2 \mid \dots \mid \b q_n \right)\)); then one can define a set of local (entry-wise) densities of states (\emph{LDoS}):
      \begin{equation}
            \mu_k ( \lambda \mid A ) = \sum_{i=1}^{n} \left| \b e_k^\top \b q_i \right|^2 \delta \left( \lambda - \lambda_i \right)
      \end{equation}
      with \( \b e_k \) being the corresponding versor. 
\end{definition}

Let us assume that \( \sigma \left(  A  \right) \subset [-1, 1] \); otherwise, one can rescale the operator such that the spectrum lands inside \( [-1, 1]\) segment (e.g. by \( A \to \frac{2}{\lambda_{\max}} A - I \))\todo{here we would need to compute at least the leading eigenvalue, but this is relatively cheap and stable, right? Right?}.



\chapter{Sparsification of Simplicial Complex}

Let \( \mc K \) be a simplicial complex with the unit weights of \( \V 1 \), \( W_1 = I \). Then \( \Lu 1 = B_2 W_2^2 B_2^\top \) and the \emph{generalized effective resistance} is given by 
\begin{equation}
      \b r = \diag \left( B_2^\top \left( \Lu 1 \right)^+ B_2 \right) = \diag \left( B_2^\top \left( B_2 W_2^2 B_2^\top \right)^+ B_2 \right)
\end{equation}
then the sparsifying measure is defined as \( \b p \sim \diag \left( W_2^2 \b r  \right)\) (let us temporary believe that this is correct and we do not need to touch it).

\begin{remark}[on the weird-weird-weird matrix inside \( \b r \)]
      Let us take a further look at GER above. Let SVD 
      \( B_2 W_2 = U S V^\top\); then 
      \begin{equation}
            \left( B_2 W_2^2 B_2^\top \right)^+ = U S^{+2} U^\top 
      \end{equation}
      and \( B_2 = U S V^\top W_2^{-1} \). As a result, 
      \begin{equation}
            B_2^\top \left( B_2 W_2^2 B_2^\top \right)^+ B_2 = W_2^{-\top} V S S^{+2} S V^\top W_2^{-1} 
      \end{equation}
      Since \( S \) and \( S^+ \) are diagonal, any permutations of \( S S^{+2} S \) are allowed. Then \( S S^{+2} S = S S^+ \). As a result for GER:  
      \begin{equation}
            \begin{aligned}
                  \b r & = \diag( X X^\top ) \\
                  \text{where } X & = W_2^{-1} V S S^+ = W_2^{-1} V \Pi = W_2^{-1} V_1 
            \end{aligned}
      \end{equation}
      where \( V_1 \) is the orthonormal basis of \( \im B_2^\top \).
\end{remark}
\end{comment}




\clearpage
%% BIBLIOGRAPHY %% 
\nocite{*}
\bibliographystyle{alpha}
\bibliography{notes}



\end{document}